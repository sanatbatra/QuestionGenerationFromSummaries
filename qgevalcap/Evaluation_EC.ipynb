{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3_VXdzRfAUeL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from bleu.bleu import Bleu\n",
    "from meteor.meteor import Meteor\n",
    "from rouge.rouge import Rouge\n",
    "from collections import defaultdict\n",
    "from argparse import ArgumentParser\n",
    "import json\n",
    "from json import encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hO1pQY_w5v6-"
   },
   "outputs": [],
   "source": [
    "# src = gold questions \n",
    "# tgt = \n",
    "# out = generated questions \n",
    "# src_file = \"../results/squad_sentences.txt\"\n",
    "# tgt_file = \"../results/squad_gold_questions.txt\"\n",
    "# out_file = \"../results/squad_generated_questions.txt\"\n",
    "# \"tgt-dev.txt\", \"tgt-dev.txt\", \"tgt-dev.txt\"\n",
    "\n",
    "path = \"cleaned_results/\"\n",
    "\n",
    "src_file = \"tgt-dev.txt\"\n",
    "tgt_file = \"tgt-dev.txt\"\n",
    "out_file = \"tgt-dev.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XcWo8omoAUeO"
   },
   "outputs": [],
   "source": [
    "class QGEvalCap:\n",
    "    def __init__(self, gts, res):\n",
    "        self.gts = gts\n",
    "        self.res = res\n",
    "\n",
    "    def evaluate(self):\n",
    "        output = []\n",
    "        scorers = [(Bleu(4), [\"Bleu_1\", \"Bleu_2\", \"Bleu_3\", \"Bleu_4\"]),\n",
    "                   #(Meteor(),\"METEOR\"),\n",
    "                   (Rouge(), \"ROUGE_L\")\n",
    "                  ]\n",
    "        \n",
    "        for scorer, method in scorers:\n",
    "            score, scores = scorer.compute_score(self.gts, self.res)\n",
    "            if type(method) == list:  #if calculating Bleu\n",
    "                for sc, scs, m in zip(score, scores, method):\n",
    "                    print (\"%s: %0.5f\"%(m, sc)) ##### need update \n",
    "                    output.append(sc)\n",
    "            else:\n",
    "                print (\"%s: %0.5f\"%(method, score)) #### need update\n",
    "                output.append(score)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1138,
     "status": "error",
     "timestamp": 1589403958283,
     "user": {
      "displayName": "Eileen Cho",
      "photoUrl": "",
      "userId": "03381570147993013394"
     },
     "user_tz": 240
    },
    "id": "SGwra5YCAUeP",
    "outputId": "23f9c9ee-bac3-4fce-b0b7-ae571c78827d"
   },
   "outputs": [],
   "source": [
    "def main(src_file, tgt_file, out_file):\n",
    "    pairs = []\n",
    "    with open(src_file, 'r', encoding = \"utf-8\") as infile:\n",
    "        for line in infile:\n",
    "            pair = {}\n",
    "            pair['tokenized_sentence'] = line[:-1]\n",
    "            pairs.append(pair)\n",
    "\n",
    "    with open(tgt_file, \"r\", encoding = \"utf-8\") as infile:\n",
    "        cnt = 0\n",
    "        for line in infile:\n",
    "            pairs[cnt]['tokenized_question'] = line[:-1]\n",
    "            cnt += 1\n",
    "\n",
    "    output = []\n",
    "    with open(out_file, 'r', encoding = \"utf-8\") as infile:\n",
    "        for line in infile:\n",
    "            line = line[:-1]\n",
    "            output.append(line)\n",
    "\n",
    "\n",
    "    for idx, pair in enumerate(pairs):\n",
    "        #print(idx)\n",
    "        pair['prediction'] = output[idx]\n",
    "\n",
    "    encoder.FLOAT_REPR = lambda o: format(o, '.4f')\n",
    "\n",
    "    res = defaultdict(lambda: [])\n",
    "    gts = defaultdict(lambda: [])\n",
    "    problem_indices = []\n",
    "    for i, pair in enumerate(pairs):\n",
    "    \n",
    "        key = pair['tokenized_sentence'].lower()\n",
    "        res[key] = [pair['prediction'].encode('utf-8').lower()]\n",
    "        ## gts \n",
    "        gts[key].append(pair['tokenized_question'].encode('utf-8').lower())\n",
    "    #print(gts)\n",
    "    #print(res)\n",
    "    QGEval = QGEvalCap(gts, res)\n",
    "    QGEval.evaluate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5if0EdFAUeU"
   },
   "source": [
    "## Comparing generated questions for sentences that have multiple answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu_1: 0.63914\n",
      "Bleu_2: 0.53453\n",
      "Bleu_3: 0.47332\n",
      "Bleu_4: 0.42412\n",
      "ROUGE_L: 0.62854\n"
     ]
    }
   ],
   "source": [
    "src_file = os.path.join(path,\"remain_multiple_set_1.txt\")\n",
    "tgt_file = os.path.join(path,\"remain_multiple_set_1.txt\")\n",
    "out_file = os.path.join(path,\"remain_multiple_set_2.txt\")\n",
    "\n",
    "main(src_file,tgt_file,out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQuAD Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing one-to-one (sentence, question) with gold standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu_1: 0.37537\n",
      "Bleu_2: 0.20901\n",
      "Bleu_3: 0.13656\n",
      "Bleu_4: 0.09469\n",
      "ROUGE_L: 0.35613\n"
     ]
    }
   ],
   "source": [
    "src_file = os.path.join(path,\"sq_squad_one_to_one_contexts.txt\")\n",
    "tgt_file = os.path.join(path,\"sq_squad_one_to_one_gold.txt\")\n",
    "out_file = os.path.join(path,\"sq_squad_one_to_one_generated.txt\")\n",
    "\n",
    "main(src_file,tgt_file,out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing one-to-many (sentence, question)  with selected gold standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu_1: 0.36160\n",
      "Bleu_2: 0.19156\n",
      "Bleu_3: 0.12215\n",
      "Bleu_4: 0.08395\n",
      "ROUGE_L: 0.33543\n"
     ]
    }
   ],
   "source": [
    "src_file = os.path.join(path,\"sq_squad_one_to_many_contexts.txt\")\n",
    "tgt_file = os.path.join(path,\"sq_squad_one_to_many_gold.txt\")\n",
    "out_file = os.path.join(path,\"sq_squad_one_to_many_generated.txt\")\n",
    "\n",
    "main(src_file,tgt_file,out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu_1: 0.36712\n",
      "Bleu_2: 0.19933\n",
      "Bleu_3: 0.12867\n",
      "Bleu_4: 0.08800\n",
      "ROUGE_L: 0.34291\n"
     ]
    }
   ],
   "source": [
    "src_file = os.path.join(path,\"sq_squad_one_to_many_multiple_contexts.txt\")\n",
    "tgt_file = os.path.join(path,\"sq_squad_one_to_many_multiple_gold.txt\")\n",
    "out_file = os.path.join(path,\"sq_squad_one_to_many_multiple_generated.txt\")\n",
    "\n",
    "main(src_file,tgt_file,out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing all (sentence, question)  with selected gold standard (Du et al. 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu_1: 0.36952\n",
      "Bleu_2: 0.20219\n",
      "Bleu_3: 0.13096\n",
      "Bleu_4: 0.08991\n",
      "ROUGE_L: 0.34651\n"
     ]
    }
   ],
   "source": [
    "src_file = os.path.join(path,\"sq_squad_all_gold.txt\")\n",
    "tgt_file = os.path.join(path,\"sq_squad_all_gold.txt\")\n",
    "out_file = os.path.join(path,\"sq_squad_all_generated.txt\")\n",
    "\n",
    "main(src_file,tgt_file,out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing (sentence, answer, question) input with gold standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu_1: 0.34180\n",
      "Bleu_2: 0.22427\n",
      "Bleu_3: 0.15740\n",
      "Bleu_4: 0.11352\n",
      "ROUGE_L: 0.31966\n"
     ]
    }
   ],
   "source": [
    "src_file = os.path.join(path,\"sqa_index.txt\")\n",
    "tgt_file = os.path.join(path,\"sqa_gold.txt\")\n",
    "out_file = os.path.join(path,\"sqa_generated.txt\")\n",
    "\n",
    "main(src_file,tgt_file,out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Narrative QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu_1: 0.30177\n",
      "Bleu_2: 0.19354\n",
      "Bleu_3: 0.13226\n",
      "Bleu_4: 0.09305\n",
      "ROUGE_L: 0.31339\n"
     ]
    }
   ],
   "source": [
    "src_file = os.path.join(path,\"nqa_indices.txt\")\n",
    "tgt_file = os.path.join(path,\"nqa_gold.txt\")\n",
    "out_file = os.path.join(path,\"nqa_generated.txt\")\n",
    "\n",
    "main(src_file,tgt_file,out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narrate QA with modified Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu_1: 0.26913\n",
      "Bleu_2: 0.16389\n",
      "Bleu_3: 0.10558\n",
      "Bleu_4: 0.07024\n",
      "ROUGE_L: 0.27481\n"
     ]
    }
   ],
   "source": [
    "src_file = os.path.join(path,\"nqa_sanat_index.txt\")\n",
    "tgt_file = os.path.join(path,\"nqa_sanat_gold.txt\")\n",
    "out_file = os.path.join(path,\"nqa_sanat_generated.txt\")\n",
    "\n",
    "main(src_file,tgt_file,out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Evaluation_debugging.ipynb",
   "provenance": [
    {
     "file_id": "1rM6RnF9XER0eywXoX3hfA8saBygqihSr",
     "timestamp": 1589304108780
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
